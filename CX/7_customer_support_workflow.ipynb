{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d48c7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import TypedDict,Literal,Dict\n",
    "from pydantic import BaseModel,Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bdb92a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652e8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c070c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(api_key=os.getenv('OPEN_AI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1409b9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: bool\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "049c2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diagnosis(BaseModel):\n",
    "    issue_type: str = Field(description=\"Which segment of products is the issue concerned to.\")\n",
    "    tone: str = Field(description='Tone of the customer')\n",
    "    urgency: str = Field(description='Urgency of the issue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d404dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZXGAMING\\miniconda3\\envs\\langchain\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(Diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b394c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: SupportState):\n",
    "    review = state['review']\n",
    "\n",
    "    prompt = f\"Find the sentiment of the following response and categorise only as Positive or Negative \\n {review}\"\n",
    "\n",
    "    sentiment = model.invoke(prompt).content\n",
    "\n",
    "    return{\n",
    "        'sentiment':sentiment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "184aaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state: SupportState):\n",
    "    review = state['review']\n",
    "\n",
    "    prompt = f'Generate a positive response based upon the review context\\n review: {review} \\n'\n",
    "\n",
    "    response = model.invoke(prompt).content\n",
    "\n",
    "    return{\n",
    "        'response':response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d66944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_inputs(review: str, analysis: Diagnosis) -> Dict:\n",
    "    return{\n",
    "        'review': review,\n",
    "        'analysis': analysis\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df42c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_response(state: SupportState):\n",
    "    review = state['review']\n",
    "\n",
    "    analysis_prompt = PromptTemplate(template='Analyse the following customer review and provide the category/type of issue, tone of customer and urgency of the issue \\n {review}',input_variables=['review'])\n",
    "\n",
    "    response_prompt = PromptTemplate(template='Based upon the negative customer review and the analysis of the review, generate a response \\n {review} \\n {analysis}',input_variables=['review','analysis'])\n",
    "\n",
    "    analysis_chain = analysis_prompt | structured_model\n",
    "\n",
    "    final_chain = analysis_chain | RunnableLambda(lambda analysis:combine_inputs(review,analysis)) | response_prompt | model | parser\n",
    "\n",
    "    response = final_chain.invoke({'review':review})\n",
    "\n",
    "    return{\n",
    "        'response': response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5e3553af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(state: SupportState) -> Literal['positive_response','negative_response']:\n",
    "    sentiment = state['sentiment']\n",
    "\n",
    "    if sentiment == 'Positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'negative_response'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ffde4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(SupportState)\n",
    "\n",
    "graph.add_node('find_sentiment',find_sentiment)\n",
    "graph.add_node('positive_response',positive_response)\n",
    "graph.add_node('negative_response',negative_response)\n",
    "\n",
    "graph.set_entry_point('find_sentiment')\n",
    "\n",
    "graph.add_conditional_edges('find_sentiment',generate_response)\n",
    "\n",
    "graph.set_finish_point('positive_response')\n",
    "graph.set_finish_point('negative_response')\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8682853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'The laptop I brought is overpriced and a crow stole it',\n",
       " 'sentiment': 'Negative',\n",
       " 'response': \"Dear valued customer,\\n\\nWe are sorry to hear about your experience with our laptop. We understand your frustration regarding the pricing and the unfortunate incident with the crow. Our team is always looking for ways to improve our products and pricing to better meet our customers' needs. \\n\\nPlease reach out to our customer service team so we can discuss possible solutions and address any concerns you may have. We apologize for any inconvenience this may have caused you and we appreciate your feedback.\\n\\nSincerely,\\n[Your Company Name]\"}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state={\n",
    "    'review': 'The laptop I brought is overpriced and a crow stole it'\n",
    "}\n",
    "\n",
    "app.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
